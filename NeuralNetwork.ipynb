{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ba37491",
   "metadata": {},
   "source": [
    "# **Neural Network without Python Library** \n",
    "*A detailed description of NN, including the maths* &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ~Nitin Rohit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2ef01",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "I was always puzzled about the internal working of neural networks and couln't just accept to use the inbuilt libraries as such without understanding the core knowledge of neural network. Sometime later I got a better grasp on it after watching the Machine Learing course by Andrew NG(which is also available in youtube), a great course to start ML. So, thought to share it to all.\n",
    "\n",
    "This notebook is made for my own understanding and for other too get a better grip in neural networks and its application. I will be using a two layered neural network for this task and will be using the MNIST dataset available in Kaggle. In this notebook I'll be explaining about every mathematical equation required to understand the working behind it and some links as reference, which will give you a easy time learning the brain of computer(aka NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805c3ef",
   "metadata": {},
   "source": [
    "### About the dataset (Modified National Institute of Standards and Technology)\n",
    "This is one of the most famous dataset of hand written number digits, from zero to nine, used in machine learning for image processing and can be a good start for machine learing enthosiast like me. The size of the images are 28x28 with each pixel value varying between 0 to 255 (from white to black). There are 60,000 examples for training the model and 10,000 examples for testing the accuracy of the model built with each example labelled as one of the digit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ade358",
   "metadata": {},
   "source": [
    "### The algorithm and mathematics\n",
    "In this code I will be using a two layer neural network which has 784 pixels as input parameters, 10 nodes in first layer and 10 nodes in second layer(also the output layer). Neural network is just multi-layered and multi-node logistic regressin with different activation function. \n",
    "So, to the algorithm now. We will be using ReLU as the acivation function for the first layer and softmax for the ouput layer. As the output layer is softmax we will be using cross entopy function, you will understand why when we get to the maths part. The part discussed now was about forward propagation which predicts the ouput for which the values of the weights and bias which should be optimised in accordance to the dataset, which has to done using backward propagation(inverse forward propagation) using gradient decent. Backward propagation is the name given to gradient decent done to all the weights and bias, as the output values of one layer become input for the next layer and using chain rule while applying differentiation we get to see that the variable depends on a backward manner hence the name \"Backward Propagation\". We have to do the back propagation multiple time so that we get the minimum accuracy to call it a ML algorithm.\n",
    "So lets sum up the things you should know before going any further. \n",
    "1. Linear algebra(Basics)\n",
    "2. Differentiation(chain rule)\n",
    "3. Einstein notation(its not that difficult as it sounds)\n",
    "4. python(numpy) \n",
    "\n",
    "That's it? I can't believe it, am I already a data scientist. NO! We havn't done the coding part yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6fcd1e",
   "metadata": {},
   "source": [
    "### THE code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea540df",
   "metadata": {},
   "source": [
    "First we have to import the required libraries<br>\n",
    "Pandas just to read the csv files, Numpy for manipulating the arrayed data and Matplotlib for the visualisation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e368e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cbdee4",
   "metadata": {},
   "source": [
    "Now we have to bring the csv file to the code and then see if we have imported the correct file by viewing the initial datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d01a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
      "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('mnist_train.csv')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c16262",
   "metadata": {},
   "source": [
    "We can see that the imported file is correct and we can now move to the next step where we have to change the data to numpy array and get the dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ed6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data)\n",
    "m,n = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53187a1e",
   "metadata": {},
   "source": [
    "Now we have to seperate the pixel's values(parameters) and labels so that we can use them as input values and comparing the correct value after the prediction is made by our model, respectively. After getting the input values we have to normalise so that it can be a better dataset as it gets contained between 0-1 and easy to manipulate(see data pre-processing for better understanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1eaf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.T\n",
    "Y_train = data[0]\n",
    "X_train = data[1:n]\n",
    "X_train = X_train / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce9d9c",
   "metadata": {},
   "source": [
    "Now lets see how the data has been converted and also the transpose has been taken due to the convention and nothing more, which will be used while explaining the maths part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c95e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ae116",
   "metadata": {},
   "source": [
    "So the data processing has been done properly and now lets move on to the next part which is Forward propagation, before that we have to intialise the weights and bias with some ramdom values(between -0.5 to 0.5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760d7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    W1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    W2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f6ce15",
   "metadata": {},
   "source": [
    "The dimension of the first weight vector is 10x784 because there are 10 nodes in next layer and 784 input parameters, and the first bias is 10x1 as its the constant that is been added to each of the next layer nodes(10 here). We can give similar explaination to the next weights and bias to get their dimensions as given above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d75f601",
   "metadata": {},
   "source": [
    "Next, we have to define the activation functions which are ReLU and softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e8ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def softmax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26bd10",
   "metadata": {},
   "source": [
    "The ReLU function returns the same value if the input is positive else returns zero. The functions can be written as above, 'cause the max(x,0) is ReLU function which can be visualised from the graph.<br>\n",
    "The softmax fucntion just takes the probabilty after each value is raised exponentially. The np.exp does the exponential part and the sum fucntions just adds all the term in the array, later just calculating the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2190d2",
   "metadata": {},
   "source": [
    "As the functions are defined, now we have to just use them in the forward propagation as following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861bc401",
   "metadata": {},
   "source": [
    "**The working of forward propagation in mathematics:**<br>\n",
    "$ Z_1=W_1*X^T+b_1 $<br>\n",
    "$ A_1=ReLU(Z_1) $<br>\n",
    "$ Z_2=W_2*A_1+b_2 $<br>\n",
    "$ A_2=softmax(Z_2) $<br><br>\n",
    "where $X$ is the input matrix and $A_2$ is the output matrix. This is just the definition of neural network where we are taking the linear combination of the nodes and passing it through a non linear function. This is a two layer neural network, so there are two such steps involved, if one has to extend this to multiple layer we just have to follow this rule like an induction. Then we have to optimise these weights and bias such that the output matches the desired output. Intially the transpose of the input matrix is taken because the features had to be multiplied with the weights and convention is to mulitple weights by the input matrix, hence the transpose is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21c4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c0b382",
   "metadata": {},
   "source": [
    "Now to the hardest part-**BACK PROPAGATION**<br>\n",
    "We have to define some function like derivative of ReLU and one hot:<br>\n",
    "der_ReLU is just the derivative of ReLU and one hot just creates an 10x1 array which has one in the correct label and rest are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97f0c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_deriv(Z):\n",
    "    return Z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) #creates array of zeros with dimension (number of samples)x10(=category)\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1         #arange works like loop here and fills the correct label as one using Y\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20388783",
   "metadata": {},
   "source": [
    "The value of ReLU_deriv is zero for negative values as it is constant and one for positive values as it is same as input<br>\n",
    "The one hot just creates a array of one and zeros as exaplained above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad5cb9",
   "metadata": {},
   "source": [
    "I'll be explaining each line of code here, as it is the most confusing part, with the mathematical equations and wordings. I would suggest you to understand the maths part as it is the basis of NN and will help to apply them later efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c9804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    I=np.ones((m,1))\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * dZ2.dot(I)\n",
    "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * dZ1.dot(I)\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f5372",
   "metadata": {},
   "source": [
    "**The working of backward propagation in mathematics:**<br>\n",
    "The cost function used here is negative logarithm of output of the correct label which should be enough as it is probability of all the classification. The value shoots to infinity if the probability is zero to the correct label and tends to zero if probability is one. So now lets write down the values of $ Z_1,Z_2,A_1,A_2 $ in einstein notation. After that we will write the cost function in terms of einstein notation and differentiate to use the gradient decent.<br><br>\n",
    "$$ Cost=-log(F) $$ where F is the probability of correct label<br>\n",
    "einstein notation is just a notation to write the summation of series in short without summation sign. So, we have to understand the limits of the variable and we can understand there is a summation if same variable comes twice.<br>\n",
    "$$ \\sum_{n=1}^N a_ix^i=a_ix^i\\,\\,(einstein\\,\\,notation) $$<br>\n",
    "Now we have to follow some rules so that we don't get confused while understading the mathematics. So, the capital letters will indicate the weights and small letters the bias, for bias there will only one subscript but for weights there will be two (right one indicating the variables from previous layer and left one the node in current layer). We will use letter n and m for first and second layer respectively. So $ _{j}N_i $ is a weight of second layer with  jth variable of ith node.<br>\n",
    "Now we write down the matrices in these form:<br>\n",
    "$$ Z_1=(_{j}M_i x_i+m_i) $$\n",
    "$$ A_1=ReLU(_{j}M_i x_i+m_i) $$ this is the value for a jth node in first layer. Similarly we get,<br>\n",
    "$$ Z_2=(_kN_jReLU(_{j}M_i x_i+m_i)+n_j) $$\n",
    "$$ A_2=\\delta((_kN_jReLU(_{j}M_i x_i+m_i)+n_j)) $$ ,here **delta** is the softmax function<br>\n",
    "Now we just have to differentiate the cost function and write down it in matrix form. But there is a catch, the differentiatoin is not so easy.<br>\n",
    "We will first find the value of this term $ \\frac{\\partial F}{\\partial _{k_0}N_{j_0}} $ and use chain rule to find the derivative of the cost fucntion, we have to do the same for the bias and for the first layer weights and bias.<br>\n",
    "Let for example assume that the correct label is three. Then our  F from cost function would look something like this.\n",
    "$$ F=\\frac{e^{(_3N_jReLU(_{j}M_i x_i+m_i)+n_j)}}{\\sum_{k=1}^{10} e^{(_kN_jReLU(_{j}M_i x_i+m_i)+n_j)}} $$<br>\n",
    "\n",
    "Now if we take differentiation with a weight that belong to the third node then that term will be there in numerator as well as denominator.\n",
    "$$ F=\\frac{e^{(_3N_jReLU(_{j}M_i x_i+m_i)+n_j)}}{\\sum_{k=1}^{10} e^{(_kN_jReLU(_{j}M_i x_i+m_i)+n_j)}}=\\frac{1}{1+pe^{q _{k_0}N_{j_0}}} $$<br>\n",
    "the LHS can be written as in RHS by dividing F with Numerator in numberator and denominator, where p and q are constant w.r.t to  $_{k_0}N_{j_0}$. If you differentiate this term you will find that it works like sigmoidal function whose derivative is F(1-F). Then the derivative for following weight can be written as:\n",
    "$$ \\frac{\\partial F}{\\partial _{3}N_{j_0}}=-\\frac{1}{F}*F(1-F) $$<br>\n",
    "but the weight has a coefficient of ReLU so the term will change to $\\frac{\\partial F}{\\partial _{3}N_{j_0}}=ReLU(_{j_0}M_i x_i+m_i)(F-1)$ and F is the softmax value of correct label.<br>Similarly if you do the differentiation of other nodes you will find the derivative to of similar form but instead of minus one it will be minus zero. So we can think of this as the computed output value minus expected value mulitplied with ReLU (this is so beautifull).<br>\n",
    "So, in genral we can write the derative of second layer as following:$$ \\frac{\\partial F}{\\partial _{k_0}N_{j_0}}=ReLU(_{j_0}M_i x_i+m_i)(\\delta_{k_0}-Y) $$ ,where $\\delta_{k_0}$ is the output value of kth node.<br>\n",
    "Similarly for bias of second layer we can write the same expression but without the ReLU part as it has no coefficient. Then we get:$$ \\frac{\\partial F}{\\partial _{k_0}n}=(\\delta_{k_0}-Y) $$<br> Now you should have understood why we have created one hot function and subtracted it with the computed output ,and why there is no ReLU term mulitplied with the bias updation. We can follow the same method to find the updation values of first layer which is little harder than this but doable(I suggest you to do it).<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a56325e",
   "metadata": {},
   "source": [
    "We have got the derivative vectors for each datapoints and now we have to update the weights and bias according to gradient decent with a suitable alpha(hyperparameter), which decides the rate of convergence in gradient decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a53ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    b2 = b2 - alpha * db2    \n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a713e5",
   "metadata": {},
   "source": [
    "We now get the predicted value by the model we have built and see how the model will perform using the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fcac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y)\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca83fcf",
   "metadata": {},
   "source": [
    "aboute the above fucntions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f938af4",
   "metadata": {},
   "source": [
    "Oof! We are almost there. Its time to put all the snipets together and see how good our model will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05b4eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.ones((500,1))\n",
    "y=np.ones((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f1dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, alpha, iterations):\n",
    "    W1, b1, W2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "        predictions = get_predictions(A2)\n",
    "        m=get_accuracy(predictions, Y)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)   \n",
    "            print(m) \n",
    "        x[i]=i\n",
    "        y[i]=m\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8167fb",
   "metadata": {},
   "source": [
    "Fingers crossed, lets hope that the model is good enough and we will check it with some exmaples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "900ad0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 8 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "Iteration:  0\n",
      "0.10376666666666666\n",
      "[8 8 1 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 1 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 1 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 1 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 1 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 8 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 0 5] [5 0 4 ... 5 6 8]\n",
      "Iteration:  10\n",
      "0.14105\n",
      "[8 3 6 ... 8 0 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 0 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 0 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "Iteration:  20\n",
      "0.22136666666666666\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 3 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "Iteration:  30\n",
      "0.30143333333333333\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 5] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "Iteration:  40\n",
      "0.3626666666666667\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "Iteration:  50\n",
      "0.41101666666666664\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "Iteration:  60\n",
      "0.45381666666666665\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 1] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  70\n",
      "0.49483333333333335\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  80\n",
      "0.5333\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  90\n",
      "0.5692333333333334\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  100\n",
      "0.6021166666666666\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  110\n",
      "0.6305333333333333\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[8 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  120\n",
      "0.6548833333333334\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  130\n",
      "0.6744666666666667\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  140\n",
      "0.6927333333333333\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  150\n",
      "0.70805\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  160\n",
      "0.7227166666666667\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  170\n",
      "0.7349666666666667\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  180\n",
      "0.7455666666666667\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 8 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  190\n",
      "0.7543833333333333\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  200\n",
      "0.76335\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  210\n",
      "0.7715166666666666\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  220\n",
      "0.7788833333333334\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  230\n",
      "0.7845\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  240\n",
      "0.7900833333333334\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  250\n",
      "0.7958833333333334\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "Iteration:  260\n",
      "0.7998833333333333\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 9] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  270\n",
      "0.8042166666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  280\n",
      "0.8079333333333333\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  290\n",
      "0.81185\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  300\n",
      "0.8153333333333334\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  310\n",
      "0.8180666666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  320\n",
      "0.821\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  330\n",
      "0.82375\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  340\n",
      "0.8268\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  350\n",
      "0.82885\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  360\n",
      "0.8312666666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  370\n",
      "0.8335166666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  380\n",
      "0.8355833333333333\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  390\n",
      "0.837\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  400\n",
      "0.8385333333333334\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  410\n",
      "0.8402333333333334\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  420\n",
      "0.8415666666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  430\n",
      "0.8431\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  440\n",
      "0.84435\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  450\n",
      "0.8457333333333333\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  460\n",
      "0.847\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  470\n",
      "0.8485333333333334\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  480\n",
      "0.8495166666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "Iteration:  490\n",
      "0.8505166666666667\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n",
      "[3 0 6 ... 5 6 8] [5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2= gradient_descent(X_train, Y_train, 0.10, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e684f",
   "metadata": {},
   "source": [
    "~85%. That's actually good for a two layered neural network. Hats off to you all if you are sticking around and pat yourself for the achievement of understanding the neural network in just one day(maybe lesser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c56cb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x199480768e0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805ff4c",
   "metadata": {},
   "source": [
    "I had created two arrays to store the values of the accuracy and iteration at each step and have plotted the graph above. We can see that the accuracy is trying to reach 100% and the rate of reaching is rapidly decreasing. We can increase the accuracy by using more iteration but it may overfit the training data hence will become a bad model. Also if you look closely the starting value of the grahp is not zero but around 0.1, this should be obvious as the the weights and bias are random values hence the probability of getting the label correct out of ten digits is 1/10=0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276bda2",
   "metadata": {},
   "source": [
    "Now we create two functions for getting the predicted labels for the training set by the first function and the second function will give the image and the predicted vaule together. Then we will try out the model for few labels and see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1924fd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(index, W1, b1, W2, b2):\n",
    "    current_image = X_train[:, index, None]\n",
    "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
    "    label = Y_train[index]\n",
    "    print(\"Prediction: \", prediction)\n",
    "    print(\"Label: \", label)\n",
    "    \n",
    "    current_image = current_image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(current_image, interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3be404b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [5]\n",
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANwklEQVR4nO3db6xU9Z3H8c9nkfpA/AMruMTiQhtjtpqsNWBMxFVTiy4hAWLYwAO1LvH2QU2q2egafVDjptHs2l191OSWGqipVBKtNY1GDLlZdzVWroZVBKpA8Ir8W+WBoA9Q+O6De9hc8M6Zy8w5cwa+71dyMzPnOzPnmxM+nHPmN2d+jggBOPP9RdMNAOgNwg4kQdiBJAg7kARhB5I4q5crs81H/0DNIsLjLe9qz277Ftt/tr3d9gPdvBeAernTcXbbkyR9IOmHknZL2ihpRURsKXkNe3agZnXs2a+WtD0idkbEEUm/k7S4i/cDUKNuwn6xpI/HPN5dLDuB7QHbw7aHu1gXgC518wHdeIcK3zhMj4hBSYMSh/FAk7rZs++WNGvM429L2tNdOwDq0k3YN0q61PYc29+StFzSi9W0BaBqHR/GR8TXtu+W9IqkSZKeioj3K+sMQKU6HnrraGWcswO1q+VLNQBOH4QdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0fGUzcjhkksuKa1fd911pfXrr7++Ze2uu+4qfW27GYYfeuih0vrIyEhpvczGjRtL6x988EHH792UrsJue5ekQ5KOSvo6IuZW0RSA6lWxZ78xIj6t4H0A1IhzdiCJbsMektbbftv2wHhPsD1ge9j2cJfrAtCFbg/jr42IPbZnSHrV9raIeG3sEyJiUNKgJNku/8QFQG262rNHxJ7i9oCk30u6uoqmAFSv47DbPsf2ucfvS1ogaXNVjQGoltuNZbZ8of0dje7NpdHTgWci4udtXsNhfI9Nnjy5tD5lypTS+ssvv1xanzdv3in3dDrYsmVLaf2aa64prX/xxRdVtnNKIsLjLe/4nD0idkr62447AtBTDL0BSRB2IAnCDiRB2IEkCDuQBJe4nuEeeeSR0vr999/fo076y759+0rrQ0NDpfVjx45V2U5PsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZz8NnH322aX1++67r2Xt3nvvrbqdE+zfv7+0/tJLL7WsrVq1qup2Juzw4cOl9c2bz7yfZmDPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJdPxT0h2tjJ+S7shVV11VWm83vXA3tm3bVlpftmxZab3dTzKjeq1+Spo9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwfXsPdDuevTLL7+8tP7kk09W2c4JPvroo9L6woULu3o9+kfbPbvtp2wfsL15zLJptl+1/WFxO7XeNgF0ayKH8asl3XLSsgckbYiISyVtKB4D6GNtwx4Rr0k6eNLixZLWFPfXSFpSbVsAqtbpOftFEbFXkiJir+0ZrZ5oe0DSQIfrAVCR2j+gi4hBSYMSF8IATep06G2/7ZmSVNweqK4lAHXoNOwvSrqjuH+HpD9U0w6AurS9nt32Wkk3SLpQ0n5JP5P0gqR1ki6RNCJpWUSc/CHeeO+V8jB+9uzZpfUdO3bUtu7t27eX1m+99dbS+pn4++lnulbXs7c9Z4+IFS1KP+iqIwA9xddlgSQIO5AEYQeSIOxAEoQdSIJLXHvgiiuuaGzdhw4dKq1Pnz69tN6ud4bmTh/s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCaZsrsCNN95YWn/mmWdK6zNmtPxVr8bt2rWrtD40NFTbutevX19aX7duXW3rPp0xZTOQHGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+wRNndp6otp9+/aVvvass/jZgE4cPXq0tD4yMlJaX7RoUcvatm3bOurpdMA4O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kwQBwBRhHr8ekSZNK63PmzCmtL126tGXt0Ucf7ain01nbPbvtp2wfsL15zLKHbX9ie1Pxt7DeNgF0ayKH8asl3TLO8v+IiCuLv5eqbQtA1dqGPSJek3SwB70AqFE3H9Ddbfvd4jC/5RfHbQ/YHrY93MW6AHSp07D/UtJ3JV0paa+kX7R6YkQMRsTciJjb4boAVKCjsEfE/og4GhHHJP1K0tXVtgWgah2F3fbMMQ+XSmLeXqDPtR0gtr1W0g2SLrS9W9LPJN1g+0pJIWmXpB/X1yI+++yz0voLL7zQm0Y6cNlll7WszZ8/v4edoG3YI2LFOIt/XUMvAGrE12WBJAg7kARhB5Ig7EAShB1IgmszJ+jw4cMtazfddFOt6z506FBpfXi4f7+JvHLlypY1ht56iz07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsEffXVVy1rQ0NDPeykvyxevLi0vmDBgtrW3e7S37feequ2dZ+O2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs/eB6dOnl9bPPffc0vrOnTurbOcEt99+e2n9iSeeKK2ff/75Ha+73Tj6bbfdVlrfsGFDx+s+E7FnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGfvgWnTppXWn3322dJ6u3H2efPmnXJPxy1durS0vmrVqtL6pEmTOl53O6tXry6tv/LKK7Wt+0zUds9ue5btIdtbbb9v+6fF8mm2X7X9YXE7tf52AXRqIofxX0v6p4j4G0nXSPqJ7e9JekDShoi4VNKG4jGAPtU27BGxNyLeKe4fkrRV0sWSFktaUzxtjaQlNfUIoAKndM5ue7ak70v6k6SLImKvNPofgu0ZLV4zIGmgyz4BdGnCYbc9RdJzku6JiM9tT+h1ETEoabB4j+ikSQDdm9DQm+3JGg36byPi+WLxftszi/pMSQfqaRFAFRxRvrP16C58jaSDEXHPmOX/JumziHjM9gOSpkXE/W3eK+Weffbs2aX1HTt2lNaPHDlSWn/88cdb1kZGRjp+rSRNmTKltN6N119/vbS+ZMmS0vrBgwcr7ObMERHjHnZP5DD+Wkm3SXrP9qZi2YOSHpO0zvZKSSOSllXQJ4CatA17RPy3pFYn6D+oth0AdeHrskAShB1IgrADSRB2IAnCDiTRdpy90pUlHWc/77zzSutPP/10aX3RokVVttNTb7zxRsva8uXLS1/7ySefVN1OCq3G2dmzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/JR0D3z++eel9bVr15bWL7jggtL6/PnzT7Wlyrz55pul9Ztvvrll7csvv6y6HZRgzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXA9+2mg3ZTPa9asaVlbuHBhV+u+8847S+tDQ0Ol9Y8//rir9ePUcT07kBxhB5Ig7EAShB1IgrADSRB2IAnCDiQxkfnZZ0n6jaS/knRM0mBEPGn7YUl3Sfrf4qkPRsRLbd6LcXagZq3G2ScS9pmSZkbEO7bPlfS2pCWS/kHS4Yh4fKJNEHagfq3CPpH52fdK2lvcP2R7q6SLq20PQN1O6Zzd9mxJ35f0p2LR3bbftf2U7aktXjNge9j2cHetAujGhL8bb3uKpP+U9POIeN72RZI+lRSS/kWjh/r/2OY9OIwHatbxObsk2Z4s6Y+SXomIfx+nPlvSHyPiijbvQ9iBmnV8IYxtS/q1pK1jg158cHfcUkmbu20SQH0m8mn8fEn/Jek9jQ69SdKDklZIulKjh/G7JP24+DCv7L3YswM16+owviqEHagf17MDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSaPuDkxX7VNJHYx5fWCzrR/3aW7/2JdFbp6rs7a9bFXp6Pfs3Vm4PR8Tcxhoo0a+99WtfEr11qle9cRgPJEHYgSSaDvtgw+sv06+99WtfEr11qie9NXrODqB3mt6zA+gRwg4k0UjYbd9i+8+2t9t+oIkeWrG9y/Z7tjc1PT9dMYfeAdubxyybZvtV2x8Wt+POsddQbw/b/qTYdptsL2yot1m2h2xvtf2+7Z8WyxvddiV99WS79fyc3fYkSR9I+qGk3ZI2SloREVt62kgLtndJmhsRjX8Bw/bfSTos6TfHp9ay/a+SDkbEY8V/lFMj4p/7pLeHdYrTeNfUW6tpxn+kBrddldOfd6KJPfvVkrZHxM6IOCLpd5IWN9BH34uI1yQdPGnxYklrivtrNPqPpeda9NYXImJvRLxT3D8k6fg0441uu5K+eqKJsF8s6eMxj3erv+Z7D0nrbb9te6DpZsZx0fFptorbGQ33c7K203j30knTjPfNtutk+vNuNRH28aam6afxv2sj4ipJfy/pJ8XhKibml5K+q9E5APdK+kWTzRTTjD8n6Z6I+LzJXsYap6+ebLcmwr5b0qwxj78taU8DfYwrIvYUtwck/V6jpx39ZP/xGXSL2wMN9/P/ImJ/RByNiGOSfqUGt10xzfhzkn4bEc8XixvfduP11avt1kTYN0q61PYc29+StFzSiw308Q22zyk+OJHtcyQtUP9NRf2ipDuK+3dI+kODvZygX6bxbjXNuBredo1Pfx4RPf+TtFCjn8jvkPRQEz206Os7kv6n+Hu/6d4krdXoYd1XGj0iWinpLyVtkPRhcTutj3p7WqNTe7+r0WDNbKi3+Ro9NXxX0qbib2HT266kr55sN74uCyTBN+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/Ax+oUuC92y0SAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(328, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25c28094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [7]\n",
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(28, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872db1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(3328, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f5d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  [0]\n",
      "Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOpklEQVR4nO3da6wUdZrH8d+DgBFFRREE5+wyEmPcaMQN0U2cbDTjTFgTvMUxQ7xwi8cbCZiNWRB1MBujbnZm1TejTCTiZSUTL+tx3Ox4JJNxNlEjBxQ5w46IYWdAAnJJBn3DAs++OMXkKKf+deiq6mp4vp+k0931dHU96Zzfqequy9/cXQCOfyOabgBAexB2IAjCDgRB2IEgCDsQxMh2LszM+OkfqJm721DTS63ZzWyGmf3BzD4zs8Vl3gtAvazV/exmdoKkTyX9QNJWSR9KmuXuv0/Mw5odqFkda/ZLJX3m7p+7+35JqyRdW+L9ANSoTNjPkfSnQc+3ZtO+wcy6zWyNma0psSwAJZX5gW6oTYUjNtPdfbmk5RKb8UCTyqzZt0rqGvT8O5K+KNcOgLqUCfuHks4zs++a2WhJP5bUU01bAKrW8ma8ux8wswWSfi3pBEkr3L2/ss4AVKrlXW8tLYzv7EDtajmoBsCxg7ADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBINo6ZDPqMXny5Nxab29vct4LLrggWe/pSQ8F8NhjjyXr77//frKO9mHNDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMIprB5g6dWqyfs899yTrt99+e25tzJgxLfU0XPv370/WTzrppFqXjyPljeJa6qAaM9siaZ+kg5IOuPv0Mu8HoD5VHEF3pbvvquB9ANSI7+xAEGXD7pLeNrM+M+se6gVm1m1ma8xsTcllASih7Gb85e7+hZlNkNRrZv/j7u8OfoG7L5e0XOIHOqBJpdbs7v5Fdr9T0uuSLq2iKQDVaznsZnaymY09/FjSDyVtqKoxANUqsxk/UdLrZnb4ff7d3f+rkq6CmT17drK+cOHCNnVy9EaPHp2sv/TSS7m1p556KjnvBx980FJPGFrLYXf3zyVdXGEvAGrErjcgCMIOBEHYgSAIOxAEYQeC4BTXNli6dGmy/sADDyTrRbu39u7d2/KylyxZkqx3dXUl60WyXbNDeuutt5LzLlu2LFnv6+trpaXjXt4prqzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAI9rNXoGhfdNH+4DPPPLPU8ufOnZtbe/7555Pznnvuucn6nDlzkvVbbrklWZ8yZUpurehvb/fu3cn6rFmzkvXVq1cn68cr9rMDwRF2IAjCDgRB2IEgCDsQBGEHgiDsQBDsZ6/AggULkvUnn3yy1Pv39PQk6/Pnz8+t7dmzp9SyixQNN71p06bcWtm/vS+//DJZTx0D8M4775RadidjPzsQHGEHgiDsQBCEHQiCsANBEHYgCMIOBFFmyGZkxo8fX2r+oqGJ582bl6ynrhtft82bNyfrN9xwQ27tiSeeSM5bdJ2As846K1l/+OGHc2vvvfdect6vv/46WT8WFa7ZzWyFme00sw2Dpp1hZr1mtim7H1dvmwDKGs5m/HOSZnxr2mJJq939PEmrs+cAOlhh2N39XUnfPubyWkkrs8crJV1XbVsAqtbqd/aJ7r5dktx9u5lNyHuhmXVL6m5xOQAqUvsPdO6+XNJy6fg9EQY4FrS6622HmU2SpOx+Z3UtAahDq2HvkTQ7ezxb0hvVtAOgLoXns5vZy5KukDRe0g5JP5H0H5J+KemvJP1R0o/cvfDE6WN5M37mzJm5tVdeeSU578iR6W9LN998c7K+atWqZP1YVfd1AFKeeeaZZP3uu++ubdl1yzufvfA7u7vnXYn/+6U6AtBWHC4LBEHYgSAIOxAEYQeCIOxAEJziOkwXXnhhbq1o11qRdevWlZofR+/6669P1ot2zX388cdVttMWrNmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAj2s7fB2rVrk/Vdu3a1qZPOUnQ556VLlybr9957b7KeusT3hAm5V1KTJN1xxx3J+rF4CixrdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0Igv3sFTAb8sq9fzFiBP9Th9LX11eq/uabbybrvb29ubWzzz47Oe9dd92VrJ944onJ+vz585P1JvBXCARB2IEgCDsQBGEHgiDsQBCEHQiCsANBsJ+9AkXDXk+bNi1ZT513LUm7d+8+2pZC6O/vT9ZnzJiRWys6V37MmDHJ+rZt25L1TlS4ZjezFWa208w2DJq2zMy2mdlH2e3qetsEUNZwNuOfkzTUv8h/c/dp2e0/q20LQNUKw+7u70ra04ZeANSozA90C8xsfbaZPy7vRWbWbWZrzGxNiWUBKKnVsP9c0lRJ0yRtl/TTvBe6+3J3n+7u01tcFoAKtBR2d9/h7gfd/ZCkX0i6tNq2AFStpbCb2aRBT6+XtCHvtQA6Q+F+djN7WdIVksab2VZJP5F0hZlNk+SStkhKX2QbSYsXL07W586d26ZOji/r16/Prd16663JeYuuQXDllVcm63PmzEnWn3vuuWS9DoVhd/dZQ0x+toZeANSIw2WBIAg7EARhB4Ig7EAQhB0IglNch+nTTz/NrR04cCA578iR6Y/5/PPPT9bHjcs9GlmStHfv3mQdR9q/f3+yPnbs2GT9vvvuS9a7urqS9SZ2vbFmB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgrOgyyJUuzKx9C2ujtWvXJusXX3xxqfcvGpp43rx5ubU9e7h84FBOO+20ZP3pp59O1m+66aZkfd++fcn66aefnqyX4e5DjiHOmh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHguB89go8+uijyfoLL7yQrI8aNSpZnzlzZrK+YsWK3NpDDz2UnDd1ueXj2VVXXZWsF+1HLzofvuhvogms2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCM5nb4MlS5Yk60X7wkePHt3ysr/66qtk/c4770zW33777ZaXLUm7d+8uNX/K1KlTk/XU8QupYxMk6bLLLkvWH3/88WT9/vvvT9br1PL57GbWZWa/MbONZtZvZguz6WeYWa+Zbcru0yMZAGjUcDbjD0j6R3e/QNLfSbrHzP5G0mJJq939PEmrs+cAOlRh2N19u7uvzR7vk7RR0jmSrpW0MnvZSknX1dQjgAoc1bHxZjZF0iWSPpA00d23SwP/EMxsQs483ZK6S/YJoKRhh93MTpH0qqRF7v5nsyF/AziCuy+XtDx7j5A/0AGdYFi73sxslAaC/pK7v5ZN3mFmk7L6JEk762kRQBUK1+w2sAp/VtJGd//ZoFKPpNmSHsvu36ilw+NA2dMdFy1alKyPHz8+t3bKKack533xxReT9XXr1iXrRfr7+0vNn3LNNdck66eeemrL7100DHdfX1/L792U4WzGXy7pVkmfmNlH2bT7NRDyX5rZfEl/lPSjWjoEUInCsLv7f0vK+4L+/WrbAVAXDpcFgiDsQBCEHQiCsANBEHYgCE5xPQZ0dXUl66khnS+66KKq2zkqI0bkr08OHTrUxk6+6eDBg8l60SmsDz74YJXtVIohm4HgCDsQBGEHgiDsQBCEHQiCsANBEHYgCPazHwcmT56cW7vtttuS8954443J+iWXXNJST4c1uZ998+bNubVHHnkkOe/KlSuT9U7GfnYgOMIOBEHYgSAIOxAEYQeCIOxAEIQdCIL97MBxhv3sQHCEHQiCsANBEHYgCMIOBEHYgSAIOxBEYdjNrMvMfmNmG82s38wWZtOXmdk2M/sou11df7sAWlV4UI2ZTZI0yd3XmtlYSX2SrpN0k6Sv3P1fh70wDqoBapd3UM1wxmffLml79nifmW2UdE617QGo21F9ZzezKZIukfRBNmmBma03sxVmNi5nnm4zW2Nma8q1CqCMYR8bb2anSPqtpEfc/TUzmyhplySX9M8a2NSfV/AebMYDNcvbjB9W2M1slKRfSfq1u/9siPoUSb9y9wsL3oewAzVr+UQYMzNJz0raODjo2Q93h10vaUPZJgHUZzi/xn9P0u8kfSLp8LV/75c0S9I0DWzGb5F0R/ZjXuq9WLMDNSu1GV8Vwg7Uj/PZgeAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRRecLJiuyT976Dn47NpnahTe+vUviR6a1WVvf11XqGt57MfsXCzNe4+vbEGEjq1t07tS6K3VrWrNzbjgSAIOxBE02Ff3vDyUzq1t07tS6K3VrWlt0a/swNon6bX7ADahLADQTQSdjObYWZ/MLPPzGxxEz3kMbMtZvZJNgx1o+PTZWPo7TSzDYOmnWFmvWa2Kbsfcoy9hnrriGG8E8OMN/rZNT38edu/s5vZCZI+lfQDSVslfShplrv/vq2N5DCzLZKmu3vjB2CY2d9L+krS84eH1jKzf5G0x90fy/5RjnP3f+qQ3pbpKIfxrqm3vGHG56jBz67K4c9b0cSa/VJJn7n75+6+X9IqSdc20EfHc/d3Je351uRrJa3MHq/UwB9L2+X01hHcfbu7r80e75N0eJjxRj+7RF9t0UTYz5H0p0HPt6qzxnt3SW+bWZ+ZdTfdzBAmHh5mK7uf0HA/31Y4jHc7fWuY8Y757FoZ/rysJsI+1NA0nbT/73J3/1tJ/yDpnmxzFcPzc0lTNTAG4HZJP22ymWyY8VclLXL3PzfZy2BD9NWWz62JsG+V1DXo+XckfdFAH0Ny9y+y+52SXtfA145OsuPwCLrZ/c6G+/kLd9/h7gfd/ZCkX6jBzy4bZvxVSS+5+2vZ5MY/u6H6atfn1kTYP5R0npl918xGS/qxpJ4G+jiCmZ2c/XAiMztZ0g/VeUNR90ianT2eLemNBnv5hk4ZxjtvmHE1/Nk1Pvy5u7f9JulqDfwiv1nS0iZ6yOnrXEkfZ7f+pnuT9LIGNuv+TwNbRPMlnSlptaRN2f0ZHdTbCxoY2nu9BoI1qaHevqeBr4brJX2U3a5u+rNL9NWWz43DZYEgOIIOCIKwA0EQdiAIwg4EQdiBIAg7EARhB4L4f/A3jZlxAzgIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(3128, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e39132",
   "metadata": {},
   "source": [
    "Now finally we check the accuracy of the testing set and see how our model performs for a foreign set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed337085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07abe457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6] [7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8572"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.array(data)\n",
    "data=data.T\n",
    "Y_test = data[0]\n",
    "X_test = data[1:n]\n",
    "X_test = X_test / 255.\n",
    "prediction=make_predictions(X_test, W1, b1, W2, b2)\n",
    "get_accuracy(prediction, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7747dda",
   "metadata": {},
   "source": [
    "Wow! We got an accuracy of ~85% again. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa062596",
   "metadata": {},
   "source": [
    "It was a pleasure talking to you guys and thank you for joining my ship for the whole trip along with this documentary notebook. I believe you must have understood the working of the neural network much better than before and hope you all continue learing more about machine learing and mathematics:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
